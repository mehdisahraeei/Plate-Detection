{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# developer: Mohammad mehdi Sahraei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RDRLWHOb7RNL",
    "outputId": "0c8a4ea2-f99c-4405-ec6b-07c8a009ad88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBMw_HhwsaUA"
   },
   "source": [
    "### install yolov7\n",
    "[link yolov7](https://github.com/augmentedstartups/yolov7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "krj8UqTX8HkK",
    "outputId": "ad668972-5216-44e8-d4e0-ff32ce3b4317"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "fatal: destination path 'yolov7' already exists and is not an empty directory.\n",
      "/content/yolov7\n"
     ]
    }
   ],
   "source": [
    "%cd /content/\n",
    "!git clone https://github.com/augmentedstartups/yolov7.git\n",
    "%cd yolov7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UuA87iiY9kP_",
    "outputId": "670e4505-719e-472f-c40d-0d8aad8d2bdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (1.21.6)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (4.6.0.66)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 8)) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 9)) (2.23.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 10)) (1.7.3)\n",
      "Collecting torch!=1.12.0,>=1.7.0\n",
      "  Using cached torch-1.13.0-cp38-cp38-manylinux1_x86_64.whl (890.2 MB)\n",
      "Collecting torchvision!=0.13.0,>=0.8.1\n",
      "  Using cached torchvision-0.14.0-cp38-cp38-manylinux1_x86_64.whl (24.3 MB)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 13)) (4.64.1)\n",
      "Requirement already satisfied: protobuf<4.21.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 14)) (3.19.6)\n",
      "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 17)) (2.9.1)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 21)) (1.3.5)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 22)) (0.11.2)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 34)) (7.9.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 35)) (5.4.8)\n",
      "Requirement already satisfied: thop in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 36)) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2022.9.24)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.10)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (11.10.3.66)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (57.4.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.3.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.8.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.51.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.15.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.4.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2022.6)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.15.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.13.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.11.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.2.2)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 34)) (2.0.10)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 34)) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 34)) (0.18.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 34)) (0.7.5)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 34)) (2.6.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 34)) (5.6.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 34)) (4.4.2)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 34)) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->-r requirements.txt (line 34)) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->-r requirements.txt (line 34)) (0.2.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->-r requirements.txt (line 34)) (0.7.0)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.5.0+cpu\n",
      "    Uninstalling torch-1.5.0+cpu:\n",
      "      Successfully uninstalled torch-1.5.0+cpu\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.6.0+cpu\n",
      "    Uninstalling torchvision-0.6.0+cpu:\n",
      "      Successfully uninstalled torchvision-0.6.0+cpu\n",
      "Successfully installed torch-1.13.0 torchvision-0.14.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "torch",
         "torchvision"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dt652ZsHsvk8"
   },
   "source": [
    "### coping the yolov trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wk9EICqdBZEc"
   },
   "outputs": [],
   "source": [
    "!cp /content/drive/MyDrive/best.pt /content/yolov7/weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTZxBcM5tLin"
   },
   "source": [
    "### installing packages for obtaining car plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Hak_THgD-Q5",
    "outputId": "2baf2a70-c8b6-4cb5-b05e-6a03a86f9241"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: easyocr in /usr/local/lib/python3.8/dist-packages (1.6.2)\n",
      "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.8/dist-packages (from easyocr) (0.14.0)\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.8/dist-packages (from easyocr) (1.11.1)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (from easyocr) (0.18.3)\n",
      "Requirement already satisfied: python-bidi in /usr/local/lib/python3.8/dist-packages (from easyocr) (0.4.2)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from easyocr) (7.1.2)\n",
      "Requirement already satisfied: Shapely in /usr/local/lib/python3.8/dist-packages (from easyocr) (1.8.5.post1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from easyocr) (1.13.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from easyocr) (6.0)\n",
      "Requirement already satisfied: pyclipper in /usr/local/lib/python3.8/dist-packages (from easyocr) (1.3.0.post4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from easyocr) (1.21.6)\n",
      "Requirement already satisfied: opencv-python-headless<=4.5.4.60 in /usr/local/lib/python3.8/dist-packages (from easyocr) (4.5.4.60)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from easyocr) (1.7.3)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.5->easyocr) (4.4.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.5->easyocr) (2.23.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch->easyocr) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch->easyocr) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch->easyocr) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch->easyocr) (11.10.3.66)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->easyocr) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->easyocr) (57.4.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from python-bidi->easyocr) (1.15.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.5->easyocr) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.5->easyocr) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.5->easyocr) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.5->easyocr) (2022.9.24)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->easyocr) (3.2.2)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->easyocr) (2.8.8)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image->easyocr) (2022.10.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->easyocr) (1.4.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->easyocr) (2.9.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DGaHJEXYFDIQ",
    "outputId": "74e0e67d-c0ae-408d-e8c9-af4c294b7b2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: deep-sort-realtime in /usr/local/lib/python3.8/dist-packages (1.3.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from deep-sort-realtime) (1.21.6)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from deep-sort-realtime) (4.6.0.66)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from deep-sort-realtime) (1.7.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install deep-sort-realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "id": "05pdvsmEFRXO",
    "outputId": "8ed03b28-c9b3-436e-a27e-388c9c478107"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.5.0+cpu\n",
      "  Using cached https://download.pytorch.org/whl/cpu/torch-1.5.0%2Bcpu-cp38-cp38-linux_x86_64.whl (127.3 MB)\n",
      "Collecting torchvision==0.6.0+cpu\n",
      "  Using cached https://download.pytorch.org/whl/cpu/torchvision-0.6.0%2Bcpu-cp38-cp38-linux_x86_64.whl (5.7 MB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch==1.5.0+cpu) (1.21.6)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from torch==1.5.0+cpu) (0.16.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.6.0+cpu) (7.1.2)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.0\n",
      "    Uninstalling torch-1.13.0:\n",
      "      Successfully uninstalled torch-1.13.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.14.0\n",
      "    Uninstalling torchvision-0.14.0:\n",
      "      Successfully uninstalled torchvision-0.14.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.5.0+cpu which is incompatible.\n",
      "torchaudio 0.13.0+cu116 requires torch==1.13.0, but you have torch 1.5.0+cpu which is incompatible.\n",
      "fastai 2.7.10 requires torch<1.14,>=1.7, but you have torch 1.5.0+cpu which is incompatible.\n",
      "fastai 2.7.10 requires torchvision>=0.8.2, but you have torchvision 0.6.0+cpu which is incompatible.\u001b[0m\n",
      "Successfully installed torch-1.5.0+cpu torchvision-0.6.0+cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "torch",
         "torchvision"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install torch==1.5.0+cpu torchvision==0.6.0+cpu -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpSmI_mPtsEJ"
   },
   "source": [
    "### importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sb2yqjKK66v4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "import torch\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort # is used for video object tracking and giving id to any frame\n",
    "from utils.general import check_img_size\n",
    "from utils.torch_utils import select_device, TracedModel\n",
    "from utils.datasets import letterbox\n",
    "from models.experimental import attempt_load\n",
    "from utils.general import non_max_suppression, scale_coords\n",
    "from utils.plots import plot_one_box, plot_one_box_PIL\n",
    "from copy import deepcopy\n",
    "import easyocr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AgGDwIAgt48w"
   },
   "source": [
    "### text and object detection with image , video , webcam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uArCE8fKIura",
    "outputId": "6c6bb8eb-c054-4c9e-96eb-3fc94b1428ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "IDetect.fuse\n",
      " Convert model to Traced-model... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:easyocr.easyocr:CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "images_n_vids_path = \"/content/drive/MyDrive/plate\"\n",
    "image_path = os.path.join(images_n_vids_path, \"plate.jpg\")\n",
    "video_path = os.path.join(images_n_vids_path, \"traffic.mp4\")\n",
    "\n",
    "savepath = \"/content/drive/MyDrive/save\"\n",
    "weights = '/content/yolov7/weight/best.pt'\n",
    "device_id = 'cpu'\n",
    "image_size = 640\n",
    "trace = True\n",
    "\n",
    "# Initialize\n",
    "device = select_device(device_id)\n",
    "half = device.type != 'cpu'  # half precision only supported on CUDA\n",
    "\n",
    "# Load model\n",
    "model = attempt_load(weights, map_location=device)  # load FP32 model\n",
    "stride = int(model.stride.max())  # model stride\n",
    "imgsz = check_img_size(image_size, s=stride)  # check img_size\n",
    "\n",
    "if trace:\n",
    "    model = TracedModel(model, device, image_size)\n",
    "\n",
    "if half:\n",
    "    model.half()  # to FP16\n",
    "    \n",
    "if device.type != 'cpu':\n",
    "    model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n",
    "\n",
    "\n",
    "# Load OCR\n",
    "reader = easyocr.Reader(['fa'])\n",
    "\n",
    "\n",
    "#detect_plate: returns plate_detections, det_confidences\n",
    "def detect_plate(source_image):\n",
    "    # Padded resize\n",
    "    img_size = 640\n",
    "    stride = 32\n",
    "    img = letterbox(source_image, img_size, stride=stride)[0]\n",
    "\n",
    "    # Convert\n",
    "    img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n",
    "    img = np.ascontiguousarray(img)\n",
    "    img = torch.from_numpy(img).to(device)\n",
    "    img = img.half() if half else img.float()  # uint8 to fp16/32\n",
    "    img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "    if img.ndimension() == 3:\n",
    "        img = img.unsqueeze(0)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        # Inference\n",
    "        pred = model(img, augment=True)[0]\n",
    "\n",
    "    # Apply NMS\n",
    "    pred = non_max_suppression(pred, 0.25, 0.45, classes=0, agnostic=True)\n",
    "\n",
    "    plate_detections = []\n",
    "    det_confidences = []\n",
    "    \n",
    "    # Process detections\n",
    "    for i, det in enumerate(pred):  # detections per image\n",
    "        if len(det):\n",
    "            # Rescale boxes from img_size to im0 size\n",
    "            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], source_image.shape).round()\n",
    "\n",
    "            # Return results\n",
    "            for *xyxy, conf, cls in reversed(det):\n",
    "                coords = [int(position) for position in (torch.tensor(xyxy).view(1, 4)).tolist()[0]]\n",
    "                plate_detections.append(coords)\n",
    "                det_confidences.append(conf.item())\n",
    "\n",
    "    return plate_detections, det_confidences\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def unsharp_mask(image, kernel_size=(5, 5), sigma=1.0, amount=2.0, threshold=0):\n",
    "    blurred = cv.GaussianBlur(image, kernel_size, sigma)\n",
    "    sharpened = float(amount + 1) * image - float(amount) * blurred\n",
    "    sharpened = np.maximum(sharpened, np.zeros(sharpened.shape))\n",
    "    sharpened = np.minimum(sharpened, 255 * np.ones(sharpened.shape))\n",
    "    sharpened = sharpened.round().astype(np.uint8)\n",
    "    if threshold > 0:\n",
    "        low_contrast_mask = np.absolute(image - blurred) < threshold\n",
    "        np.copyto(sharpened, image, where=low_contrast_mask)\n",
    "    return sharpened\n",
    "\n",
    "\n",
    "# cropping areas of plate\n",
    "def crop(image, coord):\n",
    "    cropped_image = image[int(coord[1]):int(coord[3]), int(coord[0]):int(coord[2])]\n",
    "    return cropped_image\n",
    "\n",
    "#text detection \n",
    "def ocr_plate(plate_region):\n",
    "    # Image pre-processing for more accurate OCR\n",
    "    cv.imwrite(os.path.join(savepath, \"plate_img.png\"), plate_region)\n",
    "    rescaled = cv.resize(plate_region, None, fx=1.2, fy=1.2, interpolation=cv.INTER_CUBIC)\n",
    "    grayscale = cv.cvtColor(rescaled, cv.COLOR_BGR2GRAY)\n",
    "    # OCR the preprocessed image\n",
    "    grayscale_blur = cv.medianBlur(grayscale, 1)\n",
    "    ret, thresh1 = cv.threshold(grayscale_blur, 120, 255, cv.THRESH_BINARY + cv.THRESH_OTSU) \n",
    "    cv.imwrite(os.path.join(savepath, \"grayscale_blur.png\"), grayscale_blur)\n",
    "    plate_text_easyocr = reader.readtext(grayscale_blur)\n",
    "    if plate_text_easyocr:\n",
    "        (bbox, text_easyocr, ocr_confidence) = plate_text_easyocr[0]\n",
    "        print(\"plate_text Easyocr \", text_easyocr)\n",
    "    else:\n",
    "        text_easyocr = \"_\"\n",
    "        ocr_confidence = 0\n",
    "    #if ocr_confidence == 'nan':\n",
    "    \n",
    "    return text_easyocr, ocr_confidence\n",
    "\n",
    "\n",
    "\n",
    "def get_plates_from_image(input):\n",
    "    if input is None:\n",
    "        return None\n",
    "    plate_detections, det_confidences = detect_plate(input)\n",
    "    plate_texts = []\n",
    "    ocr_confidences = []\n",
    "    detected_image = deepcopy(input)\n",
    "    for coords in plate_detections:\n",
    "        plate_region = crop(input, coords)\n",
    "        plate_text, ocr_confidence = ocr_plate(plate_region)\n",
    "        plate_texts.append(plate_text)\n",
    "        ocr_confidences.append(ocr_confidence)\n",
    "        # detected_image: display text onto image\n",
    "        detected_image = plot_one_box_PIL(coords, detected_image, label=plate_text, color=[0, 150, 255], line_thickness=2)\n",
    "    return detected_image\n",
    "\n",
    "\n",
    "def pascal_voc_to_coco(x1y1x2y2):\n",
    "    x1, y1, x2, y2 = x1y1x2y2\n",
    "    return [x1, y1, x2 - x1, y2 - y1]\n",
    "\n",
    "\n",
    "def get_best_ocr(preds, rec_conf, ocr_res, track_id):\n",
    "    for info in preds:\n",
    "    # Check if it is current track id\n",
    "        if info['track_id'] == track_id:\n",
    "          # Check if the ocr confidenence is maximum or not\n",
    "            if info['ocr_conf'] < rec_conf:\n",
    "                info['ocr_conf'] = rec_conf\n",
    "                info['ocr_txt'] = ocr_res\n",
    "            else:\n",
    "                rec_conf = info['ocr_conf']\n",
    "                ocr_res = info['ocr_txt']\n",
    "            break\n",
    "    return preds, rec_conf, ocr_res\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_plates_from_video(source):\n",
    "    if source is None:\n",
    "        return None\n",
    "    \n",
    "    # Create a VideoCapture object\n",
    "    video = cv.VideoCapture(source)\n",
    "\n",
    "    # Default resolutions of the frame are obtained. The default resolutions are system dependent.\n",
    "    # We convert the resolutions from float to integer.\n",
    "    width = int(video.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(video.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = video.get(cv.CAP_PROP_FPS)\n",
    "\n",
    "    # Define the codec and create VideoWriter object.\n",
    "    temp = f'{Path(source).stem}_temp{Path(source).suffix}'\n",
    "    export = cv.VideoWriter(temp, cv.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "    \n",
    "    # Intializing tracker\n",
    "    tracker = DeepSort(embedder_gpu=False)\n",
    "    \n",
    "    # Initializing some helper variables.\n",
    "    preds = []\n",
    "    total_obj = 0\n",
    "\n",
    "    while(True):\n",
    "        ret, frame = video.read()\n",
    "        if ret == True:\n",
    "            # Run the ANPR algorithm\n",
    "            bboxes, scores = detect_plate(frame)\n",
    "            # Convert Pascal VOC detections to COCO\n",
    "            bboxes = list(map(lambda bbox: pascal_voc_to_coco(bbox), bboxes))\n",
    "            \n",
    "            if len(bboxes) > 0:\n",
    "                # Storing all the required info in a list.\n",
    "                detections = [(bbox, score, 'number_plate') for bbox, score in zip(bboxes, scores)]\n",
    "\n",
    "                # Applying tracker.\n",
    "                # The tracker code flow: kalman filter -> target association(using hungarian algorithm) and appearance descriptor.\n",
    "                tracks = tracker.update_tracks(detections, frame=frame)\n",
    "\n",
    "                # Checking if tracks exist.\n",
    "                for track in tracks:\n",
    "                    if not track.is_confirmed() or track.time_since_update > 1:\n",
    "                        continue\n",
    "\n",
    "                    # Changing track bbox to top left, bottom right coordinates\n",
    "                    bbox = [int(position) for position in list(track.to_tlbr())]\n",
    "                    \n",
    "                    for i in range(len(bbox)):\n",
    "                        if bbox[i] < 0:\n",
    "                            bbox[i] = 0\n",
    "\n",
    "                    # Cropping the license plate and applying the OCR.\n",
    "                    plate_region = crop(frame, bbox)\n",
    "                    plate_text, ocr_confidence = ocr_plate(plate_region)\n",
    "\n",
    "                    # Storing the ocr output for corresponding track id.\n",
    "                    output_frame = {'track_id': track.track_id, 'ocr_txt': plate_text, 'ocr_conf': ocr_confidence}\n",
    "\n",
    "                    # Appending track_id to list only if it does not exist in the list\n",
    "                    # else looking for the current track in the list and updating the highest confidence of it.\n",
    "                    if track.track_id not in list(set(pred['track_id'] for pred in preds)):\n",
    "                        total_obj += 1\n",
    "                        preds.append(output_frame)\n",
    "                    else:\n",
    "                        preds, ocr_confidence, plate_text = get_best_ocr(preds, ocr_confidence, plate_text, track.track_id)\n",
    "                    \n",
    "                    # Plotting the prediction.\n",
    "                    frame = plot_one_box_PIL(bbox, frame, label=f'{str(track.track_id)}. {plate_text}', color=[255, 150, 0], line_thickness=3)\n",
    "                    cv.imshow(\"frame \", frame)\n",
    "                    keyexit = cv.waitKey(0)\n",
    "                    if keyexit == 27:\n",
    "                        break\n",
    "            # Write the frame into the output file\n",
    "            export.write(frame)\n",
    "        else:\n",
    "            break \n",
    "\n",
    "    # When everything done, release the video capture and video write objects\n",
    "    cv.destroyAllWindows()\n",
    "    video.release()\n",
    "    export.release()\n",
    "\n",
    "    # Compressing the output video for smaller size and web compatibility.\n",
    "    output = f'{Path(source).stem}_detected{Path(source).suffix}'\n",
    "    os.system(f'ffmpeg -y -i {temp} -c:v libx264 -b:v 5000k -minrate 1000k -maxrate 8000k -pass 1 -c:a aac -f mp4 /dev/null && ffmpeg -i {temp} -c:v libx264 -b:v 5000k -minrate 1000k -maxrate 8000k -pass 2 -c:a aac -movflags faststart {output}')\n",
    "    os.system(f'rm -rf {temp} ffmpeg2pass-0.log ffmpeg2pass-0.log.mbtree')\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_plates_from_webcam():\n",
    "    \n",
    "    # Create a VideoCapture object\n",
    "    video = cv.VideoCapture(0)\n",
    "\n",
    "    # Default resolutions of the frame are obtained. The default resolutions are system dependent.\n",
    "    # We convert the resolutions from float to integer.\n",
    "    width = int(video.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(video.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = video.get(cv.CAP_PROP_FPS)\n",
    "\n",
    "    # Define the codec and create VideoWriter object.\n",
    "    temp = f'cam_temp.mp4'\n",
    "    export = cv.VideoWriter(temp, cv.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "    \n",
    "    # Intializing tracker\n",
    "    tracker = DeepSort(embedder_gpu=False)\n",
    "    \n",
    "    # Initializing some helper variables.\n",
    "    preds = []\n",
    "    total_obj = 0\n",
    "    fr_count = 0\n",
    "    while(True):\n",
    "        ret, frame = video.read()\n",
    "        if ret == True:\n",
    "            \n",
    "            fr_count+=1\n",
    "            if fr_count % 10 !=0:\n",
    "                continue\n",
    "\n",
    "            # Run the ANPR algorithm\n",
    "            bboxes, scores = detect_plate(frame)\n",
    "            # Convert Pascal VOC detections to COCO\n",
    "            bboxes = list(map(lambda bbox: pascal_voc_to_coco(bbox), bboxes))\n",
    "            \n",
    "            if len(bboxes) > 0:\n",
    "                # Storing all the required info in a list.\n",
    "                detections = [(bbox, score, 'number_plate') for bbox, score in zip(bboxes, scores)]\n",
    "\n",
    "                # Applying tracker.\n",
    "                # The tracker code flow: kalman filter -> target association(using hungarian algorithm) and appearance descriptor.\n",
    "                tracks = tracker.update_tracks(detections, frame=frame)\n",
    "\n",
    "                # Checking if tracks exist.\n",
    "                for track in tracks:\n",
    "                    if not track.is_confirmed() or track.time_since_update > 1:\n",
    "                        continue\n",
    "\n",
    "                    # Changing track bbox to top left, bottom right coordinates\n",
    "                    bbox = [int(position) for position in list(track.to_tlbr())]\n",
    "                    \n",
    "                    for i in range(len(bbox)):\n",
    "                        if bbox[i] < 0:\n",
    "                            bbox[i] = 0\n",
    "\n",
    "                    # Cropping the license plate and applying the OCR.\n",
    "                    plate_region = crop(frame, bbox)\n",
    "                    plate_text, ocr_confidence = ocr_plate(plate_region)\n",
    "\n",
    "                    # Storing the ocr output for corresponding track id.\n",
    "                    output_frame = {'track_id': track.track_id, 'ocr_txt': plate_text, 'ocr_conf': ocr_confidence}\n",
    "\n",
    "                    # Appending track_id to list only if it does not exist in the list\n",
    "                    # else looking for the current track in the list and updating the highest confidence of it.\n",
    "                    if track.track_id not in list(set(pred['track_id'] for pred in preds)):\n",
    "                        total_obj += 1\n",
    "                        preds.append(output_frame)\n",
    "                    else:\n",
    "                        preds, ocr_confidence, plate_text = get_best_ocr(preds, ocr_confidence, plate_text, track.track_id)\n",
    "                    \n",
    "                    # Plotting the prediction.\n",
    "                    frame = plot_one_box_PIL(bbox, frame, label=f'{str(track.track_id)}. {plate_text}', color=[255, 150, 0], line_thickness=3)\n",
    "                    cv.imshow(\"frame \", frame)\n",
    "                    keyexit = cv.waitKey(0) \n",
    "                    if keyexit == 27:\n",
    "                        break\n",
    "            # Write the frame into the output file\n",
    "            export.write(frame)\n",
    "        else:\n",
    "            break \n",
    "\n",
    "    # When everything done, release the video capture and video write objects\n",
    "    cv.destroyAllWindows()\n",
    "    video.release()\n",
    "    export.release()\n",
    "\n",
    "    # Compressing the output video for smaller size and web compatibility.\n",
    "    output = f'cam_detected.mp4'\n",
    "    os.system(f'ffmpeg -y -i {temp} -c:v libx264 -b:v 5000k -minrate 1000k -maxrate 8000k -pass 1 -c:a aac -f mp4 /dev/null && ffmpeg -i {temp} -c:v libx264 -b:v 5000k -minrate 1000k -maxrate 8000k -pass 2 -c:a aac -movflags faststart {output}')\n",
    "    os.system(f'rm -rf {temp} ffmpeg2pass-0.log ffmpeg2pass-0.log.mbtree')\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plate_image = cv.imread(image_path)\n",
    "detected_plate_image = get_plates_from_image(plate_image)\n",
    "cv.imwrite(os.path.join(savepath, \"detected_plate.png\"), detected_plate_image)\n",
    "cv.imshow(\"detected_plate_image\",detected_plate_image)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "# # detected_plate_image = get_plates_from_video(video_path)\n",
    "\n",
    "\n",
    "# # detected_plate_webcam = get_plates_from_webcam()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uoLPzW1zPqp"
   },
   "source": [
    "Note: You need to upload your font to the path yolov7-utils , then open the plots file, put the font path in the plot_one_box PY func.\n",
    "\n",
    "\n",
    "like this. but full font path \n",
    "```\n",
    "font = ImageFont.truetype(\"Yekan.ttf\", fontsize)\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "awjRG-J6ys_e"
   },
   "outputs": [],
   "source": [
    "plate_image = cv.imread(image_path)\n",
    "detected_plate_image = get_plates_from_image(plate_image)\n",
    "cv.imwrite(os.path.join(savepath, \"detected_plate.png\"), detected_plate_image)\n",
    "cv.imshow(\"detected_plate_image\",detected_plate_image)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qZqpzwQky0r3"
   },
   "outputs": [],
   "source": [
    "#output: plate_text Easyocr  ٢٤٧٩٩ى"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSeWzybh1dGv"
   },
   "source": [
    "### for using video and webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i5kER2031Xzf"
   },
   "outputs": [],
   "source": [
    "detected_plate_image = get_plates_from_video(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JWLZ8Phx1aTI"
   },
   "outputs": [],
   "source": [
    "detected_plate_webcam = get_plates_from_webcam()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
